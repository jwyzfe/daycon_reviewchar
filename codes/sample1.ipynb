{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10745398,"sourceType":"datasetVersion","datasetId":6663812}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 단어 사전 기반 매핑 복원","metadata":{}},{"cell_type":"markdown","source":"## 1) Import ","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:51.065009Z","iopub.execute_input":"2025-02-14T05:02:51.065342Z","iopub.status.idle":"2025-02-14T05:02:51.068967Z","shell.execute_reply.started":"2025-02-14T05:02:51.065314Z","shell.execute_reply":"2025-02-14T05:02:51.068082Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 2) Data Load","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/daycon-review2/train.csv', encoding = 'utf-8-sig')\ntest = pd.read_csv('/kaggle/input/daycon-review2/test.csv', encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:52.549966Z","iopub.execute_input":"2025-02-14T05:02:52.550299Z","iopub.status.idle":"2025-02-14T05:02:52.762484Z","shell.execute_reply.started":"2025-02-14T05:02:52.550271Z","shell.execute_reply":"2025-02-14T05:02:52.761784Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 3) 단어 사전 생성","metadata":{}},{"cell_type":"code","source":"match_dict = {}\n\nfor input_text, output_text in zip(train['input'], train['output']):\n    input_words = input_text.split()\n    output_words = output_text.split()  # input과 output 컬럼을 순차적으로 가져와서 단어 단위로 분리\n    for iw, ow in zip(input_words, output_words):\n        match_dict[iw] = ow  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:54.013667Z","iopub.execute_input":"2025-02-14T05:02:54.013967Z","iopub.status.idle":"2025-02-14T05:02:54.153897Z","shell.execute_reply.started":"2025-02-14T05:02:54.013943Z","shell.execute_reply":"2025-02-14T05:02:54.153237Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## 4) 변환 적용","metadata":{}},{"cell_type":"code","source":"def replace_words(input_text, match_dict):\n    words = input_text.split() \n    replaced_words = [match_dict.get(word, word) for word in words] \n    return \" \".join(replaced_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:55.511653Z","iopub.execute_input":"2025-02-14T05:02:55.511960Z","iopub.status.idle":"2025-02-14T05:02:55.515974Z","shell.execute_reply.started":"2025-02-14T05:02:55.511934Z","shell.execute_reply":"2025-02-14T05:02:55.515193Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"converted_reviews = test['input'].apply(lambda x: replace_words(x, match_dict)).tolist()\n\n#변환된 리뷰를 리스트로 저장","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:56.518610Z","iopub.execute_input":"2025-02-14T05:02:56.518917Z","iopub.status.idle":"2025-02-14T05:02:56.550054Z","shell.execute_reply.started":"2025-02-14T05:02:56.518892Z","shell.execute_reply":"2025-02-14T05:02:56.549395Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 5) Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/daycon-review2/sample_submission.csv', encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:02:58.432035Z","iopub.execute_input":"2025-02-14T05:02:58.432361Z","iopub.status.idle":"2025-02-14T05:02:58.447016Z","shell.execute_reply.started":"2025-02-14T05:02:58.432336Z","shell.execute_reply":"2025-02-14T05:02:58.446360Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(len(submission))  # sample_submission.csv의 행 개수\nprint(len(converted_reviews))  # 변환된 리뷰 개수","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:00.953674Z","iopub.execute_input":"2025-02-14T05:03:00.953959Z","iopub.status.idle":"2025-02-14T05:03:00.959088Z","shell.execute_reply.started":"2025-02-14T05:03:00.953937Z","shell.execute_reply":"2025-02-14T05:03:00.958129Z"}},"outputs":[{"name":"stdout","text":"1689\n1689\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"submission['output'] = converted_reviews","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:02.640949Z","iopub.execute_input":"2025-02-14T05:03:02.641298Z","iopub.status.idle":"2025-02-14T05:03:02.645736Z","shell.execute_reply.started":"2025-02-14T05:03:02.641269Z","shell.execute_reply":"2025-02-14T05:03:02.645037Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"submission.to_csv('./baseline_submission.csv', index = False, encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:03.735361Z","iopub.execute_input":"2025-02-14T05:03:03.735631Z","iopub.status.idle":"2025-02-14T05:03:03.758266Z","shell.execute_reply.started":"2025-02-14T05:03:03.735611Z","shell.execute_reply":"2025-02-14T05:03:03.757504Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 2. LLM 활용 (Gemma)","metadata":{}},{"cell_type":"markdown","source":"## 1) Import ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport torch \nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:06.391029Z","iopub.execute_input":"2025-02-14T05:03:06.391385Z","iopub.status.idle":"2025-02-14T05:03:06.395509Z","shell.execute_reply.started":"2025-02-14T05:03:06.391357Z","shell.execute_reply":"2025-02-14T05:03:06.394539Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 2) Data Load","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/daycon-review2/train.csv', encoding = 'utf-8-sig')\ntest = pd.read_csv('/kaggle/input/daycon-review2/test.csv', encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:08.513272Z","iopub.execute_input":"2025-02-14T05:03:08.513607Z","iopub.status.idle":"2025-02-14T05:03:08.669706Z","shell.execute_reply.started":"2025-02-14T05:03:08.513580Z","shell.execute_reply":"2025-02-14T05:03:08.668930Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"samples = []\n\nfor i in range(10):\n    sample = f\"input : {train['input'][i]} \\n output : {train['output'][i]}\"\n    samples.append(sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:03:11.358716Z","iopub.execute_input":"2025-02-14T05:03:11.359036Z","iopub.status.idle":"2025-02-14T05:03:11.363578Z","shell.execute_reply.started":"2025-02-14T05:03:11.359009Z","shell.execute_reply":"2025-02-14T05:03:11.362526Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## 3) Model Load","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.36.2\n!pip install bitsandbytes==0.41.1\n!pip install torch==2.1.2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T02:37:07.602491Z","iopub.execute_input":"2025-02-14T02:37:07.602874Z","iopub.status.idle":"2025-02-14T02:39:03.341174Z","shell.execute_reply.started":"2025-02-14T02:37:07.602838Z","shell.execute_reply":"2025-02-14T02:39:03.340056Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.36.2\n  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (2.32.3)\nCollecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.36.2) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers==4.36.2) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.36.2) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.36.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers==4.36.2) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.36.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.36.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers==4.36.2) (2024.2.0)\nDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.48.3\n    Uninstalling transformers-4.48.3:\n      Successfully uninstalled transformers-4.48.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.36.2\nCollecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.45.2\n    Uninstalling bitsandbytes-0.45.2:\n      Successfully uninstalled bitsandbytes-0.45.2\nSuccessfully installed bitsandbytes-0.41.1\nCollecting torch==2.1.2\n  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.17.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2024.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2)\n  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.1.0 (from torch==2.1.2)\n  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2) (1.3.0)\nDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.5.147\n    Uninstalling nvidia-curand-cu12-10.3.5.147:\n      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0\n    Uninstalling torch-2.6.0:\n      Successfully uninstalled torch-2.6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.36.2 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.1.2 which is incompatible.\ntorchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.2 triton-2.1.0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"pip install -U bitsandbytes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:11:13.954645Z","iopub.execute_input":"2025-02-14T05:11:13.954971Z","iopub.status.idle":"2025-02-14T05:11:17.379215Z","shell.execute_reply.started":"2025-02-14T05:11:13.954947Z","shell.execute_reply":"2025-02-14T05:11:17.378326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.2)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type= 'nf4',\n    bnb_4bit_use_double_quant = True,\n    bnb_4bit_compute_dtype=torch.bfloat16\n    \n    \n)\nmodel_id = 'beomi/gemma-ko-7b'\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = 'right'\n\n#모델과 토크나이저를 로드한 후, pad_token을 eos_token으로 설정","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:11:17.923648Z","iopub.execute_input":"2025-02-14T05:11:17.923922Z","iopub.status.idle":"2025-02-14T05:19:05.090952Z","shell.execute_reply.started":"2025-02-14T05:11:17.923899Z","shell.execute_reply":"2025-02-14T05:19:05.089997Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95653c3f1df94dc7a785c31925d00a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ad727c94f6c4c7db8a0709774e6b20f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00006.safetensors:   0%|          | 0.00/2.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2847a7b59f644b4a82ff82411913c746"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00006.safetensors:   0%|          | 0.00/2.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9442f1980a34e34b819d99c43848ec8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00006.safetensors:   0%|          | 0.00/2.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af8ad9e79354dc19387304be71d5314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00006.safetensors:   0%|          | 0.00/2.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"651a7146c08e4ea4ba1ce768e5466dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00006.safetensors:   0%|          | 0.00/2.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8e0a9202ba414c881038941daa62c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00006.safetensors:   0%|          | 0.00/2.37G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e9fddc6fae481697e3fc688766d55c"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bf48570a2ed479e8fbba3c6d3bb9d98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3062d6b67d7454c86fdb9f6ecac0cfd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2feca14211e4026ad182a9fdd30b2f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"367ca266414241a9971fb11e9031d665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2858b116a17420ba4e55444ff89d81c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1314e3167c14e1c8df329c8a5d20873"}},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"## 4) Inference","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:27:45.831595Z","iopub.execute_input":"2025-02-14T05:27:45.831881Z","iopub.status.idle":"2025-02-14T05:27:46.605190Z","shell.execute_reply.started":"2025-02-14T05:27:45.831859Z","shell.execute_reply":"2025-02-14T05:27:46.604282Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# pandas DataFrame을 datasets.Dataset으로 변환\ndataset = Dataset.from_pandas(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:27:52.702322Z","iopub.execute_input":"2025-02-14T05:27:52.703292Z","iopub.status.idle":"2025-02-14T05:27:52.727079Z","shell.execute_reply.started":"2025-02-14T05:27:52.703255Z","shell.execute_reply":"2025-02-14T05:27:52.726382Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"pipe = pipeline(\n    task=\"text-generation\",\n    model=model, \n    tokenizer=tokenizer \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:31:21.121639Z","iopub.execute_input":"2025-02-14T05:31:21.121950Z","iopub.status.idle":"2025-02-14T05:31:21.127261Z","shell.execute_reply.started":"2025-02-14T05:31:21.121923Z","shell.execute_reply":"2025-02-14T05:31:21.126346Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"restored_reviews = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:31:31.879950Z","iopub.execute_input":"2025-02-14T05:31:31.880318Z","iopub.status.idle":"2025-02-14T05:31:31.884030Z","shell.execute_reply.started":"2025-02-14T05:31:31.880287Z","shell.execute_reply":"2025-02-14T05:31:31.882994Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"for index, row in test.iterrows():\n    query = row['input']  \n    \n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are a helpful assistant specializing in restoring obfuscated Korean reviews. \"\n                \"Your task is to transform the given obfuscated Korean review into a clear, correct, \"\n                \"and natural-sounding Korean review that reflects its original meaning. \"\n                \"Below are examples of obfuscated Korean reviews and their restored forms:\\n\\n\"\n                f\"Example, {samples}\"  \n                \"Spacing and word length in the output must be restored to the same as in the input. \"\n                \"Do not provide any description. Print only in Korean.\"\n            )\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"input : {query}, output : \"\n        },\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:32:00.697272Z","iopub.execute_input":"2025-02-14T05:32:00.697579Z","iopub.status.idle":"2025-02-14T05:32:00.826396Z","shell.execute_reply.started":"2025-02-14T05:32:00.697557Z","shell.execute_reply":"2025-02-14T05:32:00.825740Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"prompt = \"\\n\".join([m[\"content\"] for m in messages]).strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:32:09.624733Z","iopub.execute_input":"2025-02-14T05:32:09.625035Z","iopub.status.idle":"2025-02-14T05:32:09.628947Z","shell.execute_reply.started":"2025-02-14T05:32:09.625012Z","shell.execute_reply":"2025-02-14T05:32:09.627945Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"outputs = pipe(\n        prompt,\n        do_sample=True,\n        temperature=0.2,\n        top_p=0.9,\n        max_new_tokens=len(query),\n        eos_token_id=pipe.tokenizer.eos_token_id\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:32:18.400717Z","iopub.execute_input":"2025-02-14T05:32:18.401013Z","iopub.status.idle":"2025-02-14T05:33:02.395710Z","shell.execute_reply.started":"2025-02-14T05:32:18.400989Z","shell.execute_reply":"2025-02-14T05:33:02.395022Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"generated_text = outputs[0]['generated_text']\nresult = generated_text[len(prompt):].strip()\n        \n\nrestored_reviews.append(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:33:47.170596Z","iopub.execute_input":"2025-02-14T05:33:47.170925Z","iopub.status.idle":"2025-02-14T05:33:47.174823Z","shell.execute_reply.started":"2025-02-14T05:33:47.170898Z","shell.execute_reply":"2025-02-14T05:33:47.173908Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"## 5) Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/daycon-review2/sample_submission.csv', encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:34:22.950526Z","iopub.execute_input":"2025-02-14T05:34:22.950823Z","iopub.status.idle":"2025-02-14T05:34:22.969390Z","shell.execute_reply.started":"2025-02-14T05:34:22.950790Z","shell.execute_reply":"2025-02-14T05:34:22.968769Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# 부족한 길이만큼 빈 값 추가\nrestored_reviews += [''] * (len(submission) - len(restored_reviews))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:35:31.483135Z","iopub.execute_input":"2025-02-14T05:35:31.483489Z","iopub.status.idle":"2025-02-14T05:35:31.487822Z","shell.execute_reply.started":"2025-02-14T05:35:31.483462Z","shell.execute_reply":"2025-02-14T05:35:31.487004Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"print(len(restored_reviews))  # restored_reviews의 길이 확인\nprint(len(submission))  # submission의 행 수 확인\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:35:34.925071Z","iopub.execute_input":"2025-02-14T05:35:34.925418Z","iopub.status.idle":"2025-02-14T05:35:34.930395Z","shell.execute_reply.started":"2025-02-14T05:35:34.925392Z","shell.execute_reply":"2025-02-14T05:35:34.929561Z"}},"outputs":[{"name":"stdout","text":"1689\n1689\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"submission['output'] = restored_reviews","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:35:40.749731Z","iopub.execute_input":"2025-02-14T05:35:40.750019Z","iopub.status.idle":"2025-02-14T05:35:40.754345Z","shell.execute_reply.started":"2025-02-14T05:35:40.749996Z","shell.execute_reply":"2025-02-14T05:35:40.753561Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/baseline_submission.csv', index = False, encoding = 'utf-8-sig')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:36:30.073668Z","iopub.execute_input":"2025-02-14T05:36:30.073971Z","iopub.status.idle":"2025-02-14T05:36:30.080871Z","shell.execute_reply.started":"2025-02-14T05:36:30.073947Z","shell.execute_reply":"2025-02-14T05:36:30.080172Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# CSV 파일 불러오기\nfile_path = '/kaggle/working/baseline_submission.csv'\ndf = pd.read_csv(file_path)\n\n# 컬럼명 확인\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:50:12.789425Z","iopub.execute_input":"2025-02-14T05:50:12.789727Z","iopub.status.idle":"2025-02-14T05:50:12.797140Z","shell.execute_reply.started":"2025-02-14T05:50:12.789704Z","shell.execute_reply":"2025-02-14T05:50:12.796368Z"}},"outputs":[{"name":"stdout","text":"Index(['ID', 'output'], dtype='object')\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"# CSV 파일 불러오기\nfile_path = '/kaggle/working/baseline_submission.csv'\ndf = pd.read_csv(file_path)\n\n# 'restored_reviews' 컬럼에서 NaN이나 None을 빈 문자열로 처리\ndf['output'] = df['output'].fillna('')  # NaN을 빈 문자열로 대체","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:56:01.837385Z","iopub.execute_input":"2025-02-14T05:56:01.837671Z","iopub.status.idle":"2025-02-14T05:56:01.845004Z","shell.execute_reply.started":"2025-02-14T05:56:01.837647Z","shell.execute_reply":"2025-02-14T05:56:01.844230Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# 'restored_reviews'에 대해 문자열로 변환하여 처리\ndf['output'] = df['output'].apply(lambda x: str(x) if isinstance(x, str) else '')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:56:16.932579Z","iopub.execute_input":"2025-02-14T05:56:16.932910Z","iopub.status.idle":"2025-02-14T05:56:16.938223Z","shell.execute_reply.started":"2025-02-14T05:56:16.932885Z","shell.execute_reply":"2025-02-14T05:56:16.937289Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"# ground_truth와 restored_reviews 컬럼을 가져오기\n#ground_truth = df['ground_truth'].tolist()  # 실제 텍스트가 포함된 컬럼명\nrestored_reviews = df['output'].tolist()  # 복원된 텍스트가 포함된 컬럼명","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:56:19.185658Z","iopub.execute_input":"2025-02-14T05:56:19.185939Z","iopub.status.idle":"2025-02-14T05:56:19.189817Z","shell.execute_reply.started":"2025-02-14T05:56:19.185919Z","shell.execute_reply":"2025-02-14T05:56:19.188955Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"# 단어 수준으로 비교하기 위한 함수\ndef word_level_metrics(ground_truth, restored_reviews):\n    ground_truth_words = [set(review.split()) for review in ground_truth]\n    restored_words = [set(review.split()) for review in restored_reviews]\n    \n    precision_list = []\n    recall_list = []\n    f1_list = []\n    \n    for true, pred in zip(ground_truth_words, restored_words):\n        common_words = true & pred\n        precision = len(common_words) / len(pred) if len(pred) > 0 else 0\n        recall = len(common_words) / len(true) if len(true) > 0 else 0\n        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n        \n        precision_list.append(precision)\n        recall_list.append(recall)\n        f1_list.append(f1)\n\n    precision = sum(precision_list) / len(precision_list)\n    recall = sum(recall_list) / len(recall_list)\n    f1 = sum(f1_list) / len(f1_list)\n    \n    return precision, recall, f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:56:26.979363Z","iopub.execute_input":"2025-02-14T05:56:26.979683Z","iopub.status.idle":"2025-02-14T05:56:26.985355Z","shell.execute_reply.started":"2025-02-14T05:56:26.979655Z","shell.execute_reply":"2025-02-14T05:56:26.984455Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# 성능 지표 계산\nprecision, recall, f1 = word_level_metrics(ground_truth, restored_reviews)\n\n# 성능 지표 출력\nprint(f\"정밀도: {precision:.4f}\")\nprint(f\"재현율: {recall:.4f}\")\nprint(f\"F1 점수: {f1:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T05:56:30.015593Z","iopub.execute_input":"2025-02-14T05:56:30.016099Z","iopub.status.idle":"2025-02-14T05:56:30.023482Z","shell.execute_reply.started":"2025-02-14T05:56:30.016051Z","shell.execute_reply":"2025-02-14T05:56:30.022475Z"}},"outputs":[{"name":"stdout","text":"정밀도: 0.0304\n재현율: 0.5000\nF1 점수: 0.0574\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}